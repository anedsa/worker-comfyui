{
  "3": {
    "inputs": {
      "seed": [
        "229",
        3
      ],
      "steps": 20,
      "cfg": 2.4,
      "sampler_name": "dpmpp_3m_sde_gpu",
      "scheduler": "karras",
      "denoise": 1,
      "model": [
        "587",
        0
      ],
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "5",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "4": {
    "inputs": {
      "ckpt_name": "Realistic Freedom - Omega .safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "5": {
    "inputs": {
      "width": [
        "543",
        2
      ],
      "height": [
        "542",
        2
      ],
      "batch_size": [
        "541",
        2
      ]
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "6": {
    "inputs": {
      "text": [
        "515",
        0
      ],
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "7": {
    "inputs": {
      "text": "watermark, noise, text",
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "15",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "15": {
    "inputs": {
      "vae_name": "sdxl_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "229": {
    "inputs": {
      "seed": 35477111595177
    },
    "class_type": "Seed",
    "_meta": {
      "title": "Seed"
    }
  },
  "272": {
    "inputs": {
      "upscale_model": [
        "273",
        0
      ],
      "image": [
        "537",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModel",
    "_meta": {
      "title": "Upscale Image (using Model)"
    }
  },
  "273": {
    "inputs": {
      "model_name": "DAT_light_x3.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "365": {
    "inputs": {
      "seed": [
        "229",
        3
      ],
      "steps": 20,
      "cfg": 1,
      "sampler_name": "dpmpp_3m_sde_gpu",
      "scheduler": "karras",
      "denoise": 0.6,
      "model": [
        "605",
        0
      ],
      "positive": [
        "604",
        0
      ],
      "negative": [
        "606",
        0
      ],
      "latent_image": [
        "440",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "366": {
    "inputs": {
      "samples": [
        "365",
        0
      ],
      "vae": [
        "15",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "367": {
    "inputs": {
      "images": [
        "366",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "368": {
    "inputs": {
      "mask": [
        "490",
        0
      ]
    },
    "class_type": "MaskToImage",
    "_meta": {
      "title": "Convert Mask to Image"
    }
  },
  "370": {
    "inputs": {
      "images": [
        "379",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "371": {
    "inputs": {
      "resize_behavior": "source_size_unmasked",
      "image_base": [
        "627",
        0
      ],
      "image_to_paste": [
        "376",
        0
      ],
      "mask": [
        "368",
        0
      ]
    },
    "class_type": "Paste By Mask",
    "_meta": {
      "title": "Paste By Mask"
    }
  },
  "372": {
    "inputs": {
      "model_name": "bbox/face_yolov8m.pt"
    },
    "class_type": "UltralyticsDetectorProvider",
    "_meta": {
      "title": "UltralyticsDetectorProvider"
    }
  },
  "376": {
    "inputs": {
      "force_resize_width": 0,
      "force_resize_height": 0,
      "image": [
        "634",
        0
      ],
      "mask": [
        "547",
        0
      ]
    },
    "class_type": "Cut By Mask",
    "_meta": {
      "title": "Cut By Mask"
    }
  },
  "379": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "scale_by": 3,
      "image": [
        "468",
        0
      ]
    },
    "class_type": "ImageScaleBy",
    "_meta": {
      "title": "Upscale Image By"
    }
  },
  "383": {
    "inputs": {
      "text": [
        "532",
        0
      ],
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "406": {
    "inputs": {
      "images": [
        "376",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "414": {
    "inputs": {
      "bbox_threshold": 0.6,
      "bbox_dilation": 160,
      "crop_factor": 3,
      "drop_size": 10,
      "sub_threshold": 0.28,
      "sub_dilation": 0,
      "sub_bbox_expansion": 0,
      "sam_mask_hint_threshold": 0.41000000000000003,
      "post_dilation": 0,
      "bbox_detector": [
        "372",
        0
      ],
      "image": [
        "537",
        0
      ]
    },
    "class_type": "ImpactSimpleDetectorSEGS",
    "_meta": {
      "title": "Simple Detector (SEGS)"
    }
  },
  "440": {
    "inputs": {
      "pixels": [
        "450",
        0
      ],
      "vae": [
        "15",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "450": {
    "inputs": {
      "ANY": [
        "458",
        0
      ],
      "IF_TRUE": [
        "475",
        0
      ],
      "IF_FALSE": [
        "607",
        0
      ]
    },
    "class_type": "If ANY return A else B-üî¨",
    "_meta": {
      "title": "If face not detected"
    }
  },
  "458": {
    "inputs": {
      "comparison": "a > b",
      "a": [
        "471",
        2
      ],
      "b": [
        "459",
        2
      ]
    },
    "class_type": "Compare-üî¨",
    "_meta": {
      "title": "Compare if face exist"
    }
  },
  "459": {
    "inputs": {
      "image": [
        "379",
        0
      ]
    },
    "class_type": "GetImageSizeAndCount",
    "_meta": {
      "title": "Get Image Size & Count"
    }
  },
  "468": {
    "inputs": {
      "force_resize_width": 0,
      "force_resize_height": 0,
      "image": [
        "537",
        0
      ],
      "mask": [
        "368",
        0
      ]
    },
    "class_type": "Cut By Mask",
    "_meta": {
      "title": "Cut By Mask"
    }
  },
  "471": {
    "inputs": {
      "number_type": "integer",
      "number": 4
    },
    "class_type": "Constant Number",
    "_meta": {
      "title": "Constant Number"
    }
  },
  "472": {
    "inputs": {
      "images": [
        "537",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "473": {
    "inputs": {
      "ANY": [
        "458",
        0
      ],
      "IF_TRUE": [
        "272",
        0
      ],
      "IF_FALSE": [
        "565",
        0
      ]
    },
    "class_type": "If ANY return A else B-üî¨",
    "_meta": {
      "title": "if check not passed"
    }
  },
  "474": {
    "inputs": {
      "width": 160,
      "height": 160,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "475": {
    "inputs": {
      "samples": [
        "474",
        0
      ],
      "vae": [
        "15",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "490": {
    "inputs": {
      "segs": [
        "414",
        0
      ]
    },
    "class_type": "SegsToCombinedMask",
    "_meta": {
      "title": "SEGS to MASK (combined)"
    }
  },
  "502": {
    "inputs": {
      "segs": [
        "593",
        0
      ]
    },
    "class_type": "ImpactSEGSToMaskBatch",
    "_meta": {
      "title": "SEGS to Mask Batch"
    }
  },
  "507": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "473",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "515": {
    "inputs": {
      "delimiter": ", ",
      "clean_whitespace": "true",
      "text_a": [
        "531",
        0
      ],
      "text_b": [
        "519",
        0
      ],
      "text_c": [
        "533",
        0
      ]
    },
    "class_type": "Text Concatenate",
    "_meta": {
      "title": "Text Concatenate"
    }
  },
  "516": {
    "inputs": {
      "blacklist_words": "child\nyoung\nshit\nscat\ngore\nminor\nunderage\nteen",
      "replacement_text": ""
    },
    "class_type": "CR Text Blacklist",
    "_meta": {
      "title": "üî§ Text Blacklist"
    }
  },
  "519": {
    "inputs": {
      "prompt": "Man, half body selfie, wall background "
    },
    "class_type": "CR Prompt Text",
    "_meta": {
      "title": "Main Prompt"
    }
  },
  "529": {
    "inputs": {
      "blacklist_words": "child\nyoung\nshit\nscat\ngore\nminor\nunderage\nteen",
      "replacement_text": "",
      "text": [
        "533",
        0
      ]
    },
    "class_type": "CR Text Blacklist",
    "_meta": {
      "title": "üî§ Text Blacklist"
    }
  },
  "530": {
    "inputs": {
      "prompt": "face portrait"
    },
    "class_type": "CR Prompt Text",
    "_meta": {
      "title": "‚öôÔ∏è CR Prompt Text"
    }
  },
  "531": {
    "inputs": {
      "prompt": "cinematic, realistic, 4k, (sharp detailed skin:0.6), (skin pores:0.6) (skin texture:0.6) (goose bumps:0.6)"
    },
    "class_type": "CR Prompt Text",
    "_meta": {
      "title": "‚öôÔ∏è CR Prompt Text"
    }
  },
  "532": {
    "inputs": {
      "delimiter": ", ",
      "clean_whitespace": "true",
      "text_a": [
        "530",
        0
      ],
      "text_b": [
        "529",
        0
      ]
    },
    "class_type": "Text Concatenate",
    "_meta": {
      "title": "Text Concatenate"
    }
  },
  "533": {
    "inputs": {
      "prompt": ""
    },
    "class_type": "CR Prompt Text",
    "_meta": {
      "title": "Face prompt"
    }
  },
  "537": {
    "inputs": {
      "image": [
        "8",
        0
      ]
    },
    "class_type": "ImpactImageBatchToImageList",
    "_meta": {
      "title": "Image Batch to Image List"
    }
  },
  "541": {
    "inputs": {
      "number_type": "integer",
      "number": 1
    },
    "class_type": "Constant Number",
    "_meta": {
      "title": "Batch size"
    }
  },
  "542": {
    "inputs": {
      "number_type": "integer",
      "number": 1200
    },
    "class_type": "Constant Number",
    "_meta": {
      "title": "Height"
    }
  },
  "543": {
    "inputs": {
      "number_type": "integer",
      "number": 800.5
    },
    "class_type": "Constant Number",
    "_meta": {
      "title": "width"
    }
  },
  "546": {
    "inputs": {
      "string": "[time(%Y-%m-%d)]/model1a_female"
    },
    "class_type": "String to Text",
    "_meta": {
      "title": "Output path"
    }
  },
  "547": {
    "inputs": {
      "mask": [
        "548",
        0
      ]
    },
    "class_type": "MaskToImage",
    "_meta": {
      "title": "Convert Mask to Image"
    }
  },
  "548": {
    "inputs": {
      "amount": 126,
      "device": "gpu",
      "mask": [
        "550",
        0
      ]
    },
    "class_type": "MaskBlur+",
    "_meta": {
      "title": "üîß Mask Blur"
    }
  },
  "549": {
    "inputs": {
      "image": [
        "366",
        0
      ]
    },
    "class_type": "GetImageSizeAndCount",
    "_meta": {
      "title": "Get Image Size & Count"
    }
  },
  "550": {
    "inputs": {
      "shape": "circle",
      "frames": 1,
      "location_x": [
        "554",
        2
      ],
      "location_y": [
        "551",
        2
      ],
      "grow": 0,
      "frame_width": [
        "549",
        1
      ],
      "frame_height": [
        "549",
        2
      ],
      "shape_width": [
        "558",
        2
      ],
      "shape_height": [
        "557",
        2
      ]
    },
    "class_type": "CreateShapeMask",
    "_meta": {
      "title": "Create Shape Mask"
    }
  },
  "551": {
    "inputs": {
      "operation": "division",
      "number_a": [
        "553",
        0
      ],
      "number_b": [
        "552",
        0
      ]
    },
    "class_type": "Number Operation",
    "_meta": {
      "title": "Number Operation"
    }
  },
  "552": {
    "inputs": {
      "number_type": "integer",
      "number": 2
    },
    "class_type": "Constant Number",
    "_meta": {
      "title": "Constant Number"
    }
  },
  "553": {
    "inputs": {
      "int": [
        "549",
        2
      ]
    },
    "class_type": "Int To Number (mtb)",
    "_meta": {
      "title": "Int To Number (mtb)"
    }
  },
  "554": {
    "inputs": {
      "operation": "division",
      "number_a": [
        "555",
        0
      ],
      "number_b": [
        "552",
        0
      ]
    },
    "class_type": "Number Operation",
    "_meta": {
      "title": "Number Operation"
    }
  },
  "555": {
    "inputs": {
      "int": [
        "549",
        1
      ]
    },
    "class_type": "Int To Number (mtb)",
    "_meta": {
      "title": "Int To Number (mtb)"
    }
  },
  "556": {
    "inputs": {
      "number_type": "float",
      "number": 0.7000000000000001
    },
    "class_type": "Constant Number",
    "_meta": {
      "title": "Constant Number"
    }
  },
  "557": {
    "inputs": {
      "operation": "multiplication",
      "number_a": [
        "553",
        0
      ],
      "number_b": [
        "556",
        0
      ]
    },
    "class_type": "Number Operation",
    "_meta": {
      "title": "Number Operation"
    }
  },
  "558": {
    "inputs": {
      "operation": "multiplication",
      "number_a": [
        "555",
        0
      ],
      "number_b": [
        "556",
        0
      ]
    },
    "class_type": "Number Operation",
    "_meta": {
      "title": "Number Operation"
    }
  },
  "559": {
    "inputs": {
      "images": [
        "547",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "562": {
    "inputs": {
      "number_type": "integer",
      "number": 200
    },
    "class_type": "Constant Number",
    "_meta": {
      "title": "Constant Number"
    }
  },
  "564": {
    "inputs": {
      "comparison": "a < b",
      "a": [
        "549",
        1
      ],
      "b": [
        "562",
        2
      ]
    },
    "class_type": "Compare-üî¨",
    "_meta": {
      "title": "not a face to paste"
    }
  },
  "565": {
    "inputs": {
      "ANY": [
        "564",
        0
      ],
      "IF_TRUE": [
        "272",
        0
      ],
      "IF_FALSE": [
        "371",
        0
      ]
    },
    "class_type": "If ANY return A else B-üî¨",
    "_meta": {
      "title": "If a face is upscaled"
    }
  },
  "578": {
    "inputs": {
      "instantid_file": "ip-adapter.bin"
    },
    "class_type": "InstantIDModelLoader",
    "_meta": {
      "title": "Load InstantID Model"
    }
  },
  "579": {
    "inputs": {
      "provider": "CUDA"
    },
    "class_type": "InstantIDFaceAnalysis",
    "_meta": {
      "title": "InstantID Face Analysis"
    }
  },
  "580": {
    "inputs": {
      "control_net_name": "control instant iD.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "581": {
    "inputs": {
      "ip_weight": 1,
      "cn_strength": 0.8300000000000001,
      "start_at": 0,
      "end_at": 1,
      "noise": 0,
      "combine_embeds": "norm average",
      "instantid": [
        "578",
        0
      ],
      "insightface": [
        "579",
        0
      ],
      "control_net": [
        "580",
        0
      ],
      "image": [
        "586",
        0
      ],
      "model": [
        "591",
        0
      ],
      "positive": [
        "383",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "image_kps": [
        "379",
        0
      ]
    },
    "class_type": "ApplyInstantIDAdvanced",
    "_meta": {
      "title": "Apply InstantID Advanced"
    }
  },
  "586": {
    "inputs": {
      "image": "279450672_3121128994820975_5577911162902908808_n.jpg"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "587": {
    "inputs": {
      "weight": 0.8,
      "weight_faceidv2": 0.85,
      "weight_type": "ease out",
      "combine_embeds": "concat",
      "start_at": 0,
      "end_at": 1,
      "embeds_scaling": "K+V",
      "model": [
        "590",
        0
      ],
      "ipadapter": [
        "590",
        1
      ],
      "image": [
        "586",
        0
      ],
      "clip_vision": [
        "588",
        0
      ],
      "insightface": [
        "589",
        0
      ]
    },
    "class_type": "IPAdapterFaceID",
    "_meta": {
      "title": "IPAdapter FaceID"
    }
  },
  "588": {
    "inputs": {
      "clip_name": "CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "589": {
    "inputs": {
      "provider": "CUDA"
    },
    "class_type": "IPAdapterInsightFaceLoader",
    "_meta": {
      "title": "IPAdapter InsightFace Loader"
    }
  },
  "590": {
    "inputs": {
      "preset": "FACEID PLUS V2",
      "lora_strength": 0.3,
      "provider": "CUDA",
      "model": [
        "4",
        0
      ]
    },
    "class_type": "IPAdapterUnifiedLoaderFaceID",
    "_meta": {
      "title": "IPAdapter Unified Loader FaceID"
    }
  },
  "591": {
    "inputs": {
      "weight": 0.2,
      "weight_type": "linear",
      "combine_embeds": "norm average",
      "start_at": 0,
      "end_at": 1,
      "embeds_scaling": "V only",
      "model": [
        "592",
        0
      ],
      "ipadapter": [
        "592",
        1
      ],
      "image": [
        "586",
        0
      ],
      "clip_vision": [
        "597",
        0
      ]
    },
    "class_type": "IPAdapterAdvanced",
    "_meta": {
      "title": "IPAdapter Advanced"
    }
  },
  "592": {
    "inputs": {
      "preset": "PLUS (high strength)",
      "model": [
        "587",
        0
      ]
    },
    "class_type": "IPAdapterUnifiedLoader",
    "_meta": {
      "title": "IPAdapter Unified Loader"
    }
  },
  "593": {
    "inputs": {
      "target": "area(=w*h)",
      "order": true,
      "take_start": 0,
      "take_count": 1,
      "segs": [
        "414",
        0
      ]
    },
    "class_type": "ImpactSEGSOrderedFilter",
    "_meta": {
      "title": "SEGS Filter (ordered)"
    }
  },
  "597": {
    "inputs": {
      "clip_name": "CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "604": {
    "inputs": {
      "ANY": [
        "458",
        0
      ],
      "IF_TRUE": [
        "6",
        0
      ],
      "IF_FALSE": [
        "581",
        1
      ]
    },
    "class_type": "If ANY return A else B-üî¨",
    "_meta": {
      "title": "If face not detected"
    }
  },
  "605": {
    "inputs": {
      "ANY": [
        "458",
        0
      ],
      "IF_TRUE": [
        "4",
        0
      ],
      "IF_FALSE": [
        "581",
        0
      ]
    },
    "class_type": "If ANY return A else B-üî¨",
    "_meta": {
      "title": "If face not detected"
    }
  },
  "606": {
    "inputs": {
      "ANY": [
        "458",
        0
      ],
      "IF_TRUE": [
        "7",
        0
      ],
      "IF_FALSE": [
        "581",
        2
      ]
    },
    "class_type": "If ANY return A else B-üî¨",
    "_meta": {
      "title": "If face not detected"
    }
  },
  "607": {
    "inputs": {
      "ANY": [
        "608",
        0
      ],
      "IF_TRUE": [
        "612",
        0
      ],
      "IF_FALSE": [
        "379",
        0
      ]
    },
    "class_type": "If ANY return A else B-üî¨",
    "_meta": {
      "title": "If face too big"
    }
  },
  "608": {
    "inputs": {
      "comparison": "a > b",
      "a": [
        "459",
        2
      ],
      "b": [
        "609",
        2
      ]
    },
    "class_type": "Compare-üî¨",
    "_meta": {
      "title": "Compare image size"
    }
  },
  "609": {
    "inputs": {
      "number_type": "integer",
      "number": 1600
    },
    "class_type": "Constant Number",
    "_meta": {
      "title": "Constant Number"
    }
  },
  "612": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "scale_by": 1,
      "image": [
        "468",
        0
      ]
    },
    "class_type": "ImageScaleBy",
    "_meta": {
      "title": "Upscale Image By"
    }
  },
  "627": {
    "inputs": {
      "upscale_model": [
        "630",
        0
      ],
      "image": [
        "272",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModel",
    "_meta": {
      "title": "Upscale Image (using Model)"
    }
  },
  "628": {
    "inputs": {
      "upscale_model": [
        "273",
        0
      ],
      "image": [
        "366",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModel",
    "_meta": {
      "title": "Upscale Image (using Model)"
    }
  },
  "629": {
    "inputs": {
      "upscale_model": [
        "630",
        0
      ],
      "image": [
        "366",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModel",
    "_meta": {
      "title": "Upscale Image (using Model)"
    }
  },
  "630": {
    "inputs": {
      "model_name": "x1_ITF_SkinDiffDetail_Lite_v1.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "634": {
    "inputs": {
      "ANY": [
        "608",
        0
      ],
      "IF_TRUE": [
        "628",
        0
      ],
      "IF_FALSE": [
        "629",
        0
      ]
    },
    "class_type": "If ANY return A else B-üî¨",
    "_meta": {
      "title": "If face too big"
    }
  }
}